{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "import librosa\n",
    "import librosa.display as DSP\n",
    "import librosa as lr\n",
    "from tempfile import mktemp\n",
    "import imagehash\n",
    "from PIL import Image\n",
    "\n",
    "import pylab\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import os\n",
    "import wave\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from scipy.io.wavfile import read\n",
    "import python_speech_features as mfcc\n",
    "from sklearn.mixture import GaussianMixture \n",
    "from sklearn.metrics import f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta(array):\n",
    "   \n",
    "    rows, cols = array.shape\n",
    "    # print(rows)\n",
    "    # print(cols)\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:\n",
    "                first =0\n",
    "            else:\n",
    "                first = i-j\n",
    "            if i+j > rows-1:\n",
    "                second = rows-1\n",
    "            else:\n",
    "                second = i+j \n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio,rate):\n",
    "       \n",
    "    mfcc_feature = mfcc.mfcc(audio, rate, 0.025, 0.01, 20, nfft = 2205, appendEnergy = True)    \n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "#     print(mfcc_feature)\n",
    "    delta = calculate_delta(mfcc_feature)\n",
    "    combined = np.hstack((mfcc_feature, delta)) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "lstFolders = [\"Marina\", \"Mohab\", \"Yousef\"]\n",
    "for lst in lstFolders:\n",
    "    listFiles = glob.glob(r\"Training Data\\{}\\*\".format(lst))\n",
    "    features = np.asarray(())\n",
    "    finishCounter = len(listFiles)\n",
    "    counter = 1\n",
    "    for file in listFiles:\n",
    "        try:\n",
    "            audio, sr = librosa.load(file)\n",
    "            vector = extract_features(audio, sr)\n",
    "            \n",
    "            if features.size == 0:\n",
    "                features = vector\n",
    "            else:\n",
    "                features = np.vstack((features, vector))\n",
    "                \n",
    "            X_test.append(vector)\n",
    "            y_test.append(lstFolders.index(lst))\n",
    "                \n",
    "            counter += 1\n",
    "            if(counter == finishCounter):\n",
    "                gmm = GaussianMixture(n_components = 6, max_iter = 200, covariance_type='diag', n_init = 3)\n",
    "                gmm.fit(features)\n",
    "                \n",
    "                # dumping the trained gaussian model\n",
    "                picklefile = lst + \".joblib\"\n",
    "                joblib.dump(gmm, picklefile) \n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Marina.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m gmm_files \u001b[39m=\u001b[39m [ i \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.joblib\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mMarina\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mMohab\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mYousef\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m----> 3\u001b[0m models    \u001b[39m=\u001b[39m [joblib\u001b[39m.\u001b[39mload(fname) \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m gmm_files]\n",
      "Cell \u001b[1;32mIn [26], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m gmm_files \u001b[39m=\u001b[39m [ i \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.joblib\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mMarina\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mMohab\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mYousef\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m----> 3\u001b[0m models    \u001b[39m=\u001b[39m [joblib\u001b[39m.\u001b[39;49mload(fname) \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m gmm_files]\n",
      "File \u001b[1;32mc:\\Users\\Yousef\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[39mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Marina.joblib'"
     ]
    }
   ],
   "source": [
    "gmm_files = [ i + '.joblib' for i in [\"Marina\", \"Mohab\", \"Yousef\"]]\n",
    "\n",
    "models    = [joblib.load(fname) for fname in gmm_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_y = []\n",
    "y = []\n",
    "for i in X_test:\n",
    "    log_likelihood = np.zeros(len(models)) \n",
    "    for j in range(len(models)):\n",
    "        gmm = models[j] \n",
    "        scores = np.array(gmm.score(i))\n",
    "        log_likelihood[j] = scores.sum()\n",
    "    y.append(log_likelihood)\n",
    "\n",
    "    winner = np.argmax(log_likelihood)\n",
    "    print(\"\\t detected as -\",models[winner])\n",
    "    final_y.append(winner)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yousef\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1599: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(final_y, y_test, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "file = r'C:\\Users\\DELL\\Desktop\\simple-recorder3\\Training Data word\\Open_book\\rahma_open_book6 (4).wav'\n",
    "audio, sr = librosa.load(file)\n",
    "vector = extract_features(audio, sr)\n",
    "og_likelihood = np.zeros(len(models)) \n",
    "for i in range(len(models)):\n",
    "    gmm    = models[i] \n",
    "    scores = np.array(gmm.score(vector))\n",
    "    log_likelihood[i] = scores.sum()\n",
    "y.append(log_likelihood)\n",
    "\n",
    "winner = np.argmax(log_likelihood)\n",
    "print(winner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4fb3601a44824cb0274fa56d765fd17850c62f4a19953a7dae862caad4cd7a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
