{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d71cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install librosa\n",
    "!pip install --upgrade sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "561083a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The output of this section is the CSV files with the data to be handle by the model\n",
    "CREATE_CSV_FILES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5a3a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the names of the CSV files\n",
    "TRAIN_CSV_FILE = \"Speaker_Train_File.csv\"\n",
    "TEST_CSV_FILE = \"Speaker_Test_File.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3383da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import zipfile as zf\n",
    "import csv\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "# import zipfile as zf\n",
    "from sklearn import svm\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e5278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWavFeatures(soundFilesFolder, csvFileName):\n",
    "    print(\"The features of the files in the folder \"+soundFilesFolder+\" will be saved to \"+csvFileName)\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "    for i in range(1, 41):\n",
    "        header += f' mfcc{i}'\n",
    "    header += ' label'\n",
    "    header = header.split()\n",
    "#     print('CSV Header: ', header)\n",
    "    file = open(csvFileName, 'w', newline='')\n",
    "    #with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    for filename in os.listdir(soundFilesFolder):\n",
    "        if filename.endswith('.wav'):\n",
    "            number = f'{soundFilesFolder}/{filename}'\n",
    "            y, sr = librosa.load(number, mono=True)\n",
    "            # remove leading and trailing silence\n",
    "            y, index = librosa.effects.trim(y)\n",
    "            chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "            rmse = librosa.feature.rms(y=y)\n",
    "            spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "            spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "            rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "            zcr = librosa.feature.zero_crossing_rate(y)\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc = 40)\n",
    "            to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "            for e in mfcc:\n",
    "                to_append += f' {np.mean(e)}'\n",
    "            writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "    print(\"End of extractWavFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd86d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (CREATE_CSV_FILES == True):\n",
    "    extractWavFeatures(\"Audio_Data/Speaker_recognition_train_data\", TRAIN_CSV_FILE)\n",
    "    extractWavFeatures(\"Audio_Data/Speaker_recognition_test_data\", TEST_CSV_FILE)\n",
    "    print(\"CSV files are created\")\n",
    "else:\n",
    "    print(\"CSV files creation is skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a414a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading a dataset and convert file name to corresbonding number\n",
    "def preProcessData(csvFileName):\n",
    "    header_name_list = ['filename', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20', 'mfcc21', 'mfcc22', 'mfcc23', 'mfcc24', 'mfcc25', 'mfcc26', 'mfcc27', 'mfcc28', 'mfcc29', 'mfcc30', 'mfcc31', 'mfcc32', 'mfcc33', 'mfcc34', 'mfcc35', 'mfcc36', 'mfcc37', 'mfcc38', 'mfcc39', 'mfcc40', 'label']\n",
    "    print(csvFileName+ \" will be preprocessed\")\n",
    "    data =  pd.read_csv(csvFileName)\n",
    "#     data = pd.read_csv(csvFileName, skiprows=[1, 50]\n",
    "    # we have 4 speakers: \n",
    "    # 0: Marina\n",
    "    # 1: Mohab\n",
    "    # 2: Omnia\n",
    "    # 3: Youssef\n",
    "    filenameArray = data['filename'] \n",
    "    speakerArray = []\n",
    "#     print(filenameArray)\n",
    "    for filename in filenameArray:\n",
    "        #print(speaker)\n",
    "        if \"marina\" in filename:\n",
    "            speaker = 0\n",
    "        elif \"mohab\" in filename:\n",
    "            speaker = 1\n",
    "        elif \"yousef\" in filename:\n",
    "            speaker = 2\n",
    "        elif \"omnia\" in filename:\n",
    "            speaker = 3\n",
    "        else: \n",
    "            speaker = 4\n",
    "#         print(speaker)\n",
    "        speakerArray.append(speaker)\n",
    "    data['number'] = speakerArray\n",
    "    #Dropping unnecessary columns\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    data = data.drop(['label'],axis=1)\n",
    "    data = data.drop(['chroma_stft'],axis=1)\n",
    "#     data.shape\n",
    "#     print(\"Preprocessing is finished\")\n",
    "#     print(data[['filename', 'number']])\n",
    "#     print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b55a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker_Train_File.csv will be preprocessed\n",
      "Speaker_Test_File.csv will be preprocessed\n"
     ]
    }
   ],
   "source": [
    "trainData = preProcessData(TRAIN_CSV_FILE)\n",
    "testData = preProcessData(TEST_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90711a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y from training data: (238,)\n",
      "Y from test data: (55,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(trainData.iloc[:, :-1], dtype = float)\n",
    "y_train = trainData.iloc[:, -1]\n",
    "X_test = np.array(testData.iloc[:, :-1], dtype = float)\n",
    "y_test = testData.iloc[:, -1]\n",
    "\n",
    "print(\"Y from training data:\", y_train.shape)\n",
    "print(\"Y from test data:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ab67d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTC = DecisionTreeClassifier()\n",
    "DTC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f20acd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 4, 4, 0, 1, 3, 2, 2, 1, 3, 4, 3, 2, 2, 1, 4, 2, 0, 2, 0,\n",
       "       2, 3, 1, 0, 3, 0, 4, 4, 1, 2, 2, 2, 0, 1, 1, 4, 2, 1, 2, 3, 3, 1,\n",
       "       3, 4, 3, 0, 0, 4, 0, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_decision_tree = DTC.predict(X_test)\n",
    "test_pred_decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "525798e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio = 'Audio_Data/open_test2.wav'\n",
    "audio_features = extract_features_from_input(input_audio)\n",
    "audio_features = audio_features.reshape(1,45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa43b4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_dtr1: 0.8545454545454545\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_dtr1:\",metrics.accuracy_score(y_test, test_pred_decision_tree))\n",
    "# print(test_pred_decision_tree)\n",
    "# print( y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8241674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_input(input_audio):\n",
    "    extracted_features = []\n",
    "    y, sr = librosa.load(input_audio, mono=True, duration=30)\n",
    "    y, index = librosa.effects.trim(y)\n",
    "#     chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc = 40)\n",
    "    extracted_features.extend([np.mean(rmse), np.mean(spec_cent),np.mean(spec_bw), np.mean(rolloff), np.mean(zcr)])\n",
    "    for e in mfcc:\n",
    "        extracted_features.append(np.mean(e))\n",
    "    return np.array(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d5c3f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voice of Omnia\n"
     ]
    }
   ],
   "source": [
    "prediction = DTC.predict(np.array(audio_features))\n",
    "speakers_list = [(0, 'Marina'), (1, 'Mohab'), (2, 'Yousef'), (3, 'Omnia'), (4, 'Others')]\n",
    "for iterator, speaker in enumerate(speakers_list):\n",
    "    if prediction[0] == speaker[0]:\n",
    "        print(\"voice of \" + speaker[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36c05b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "import pickle\n",
    "filename = 'speech_classifier_final.sav'\n",
    "pickle.dump(DTC, open(filename, 'wb'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c3fecd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_GMM: 0.38181818181818183\n"
     ]
    }
   ],
   "source": [
    "gmm = GaussianMixture(n_components=4, covariance_type='full').fit(X_train)\n",
    "prediction_gmm = gmm.predict(X_test)\n",
    "print(\"Accuracy_GMM:\",metrics.accuracy_score(y_test, prediction_gmm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d88204",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a50b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "15e1261e11fdca25e1fbe3087b6514fdf2e8ee3a6a852c5a4ca2a1dd4c5422d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
